# Awesome-Image-Captioning
Image captioning paper tag cluster

|paper|tags|link|code|
|---|---|---|---|
|Engaging Image Captioning via Personality|new dataset,CVPR2019,CVPR,diversity|https://arxiv.org/pdf/1810.10665.pdf|
|Point Novel Objects in Image Captioning|CVPR2019,CVPR,novel object captioning,object detection|https://arxiv.org/pdf/1904.11251.pdf|
|Exact Adversarial Attack to Image Captioning via Structured Output Learning with Latent Variables|CVPR2019,CVPR,model attack,GAN|http://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Exact_Adversarial_Attack_to_Image_Captioning_via_Structured_Output_Learning_CVPR_2019_paper.pdf|
|MSCap: Multi-Style Image Captioning with Unpaired Stylized Text|CVPR2019,CVPR,style,unpaired|http://openaccess.thecvf.com/content_CVPR_2019/papers/Guo_MSCap_Multi-Style_Image_Captioning_With_Unpaired_Stylized_Text_CVPR_2019_paper.pdf|
|Self-critical n-step Training for Image Captioning|CVPR2019,CVPR,RL|https://arxiv.org/pdf/1904.06861.pdf|
|Look Back and Predict Forward in Image Captioning|CVPR2019,CVPR,model|http://openaccess.thecvf.com/content_CVPR_2019/papers/Qin_Look_Back_and_Predict_Forward_in_Image_Captioning_CVPR_2019_paper.pdf|
|Intention Oriented Image Captions with Guiding Objects|CVPR2019,CVPR,controllable,novel image captioning|https://arxiv.org/pdf/1811.07662.pdf|
|Adversarial Semantic Alignment for Improved Image Captions|CVPR2019,CVPR,diversity,GAN,novel image captioning|https://arxiv.org/pdf/1805.00063.pdf|
|Good News, Everyone! Context driven entity-aware captioning for news images|CVPR2019,CVPR,new dataset,novel image captioning,template|https://arxiv.org/pdf/1904.01475.pdf|https://github.com/furkanbiten/GoodNews
|Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions|CVPR2019,CVPR,controllable,diversity,object detection|https://arxiv.org/pdf/1811.10652.pdf|https://github.com/aimagelab/show-control-and-tell
|Dense Relational Captioning:Triple-Stream Networks for Relationship-Based Captioning|CVPR2019,CVPR,dense captioning,template,object detection|https://arxiv.org/pdf/1903.05942.pdf|https://github.com/Dong-JinKim/DenseRelationalCaptioning
|Context and Attribute Grounded Dense Captioning|CVPR2019,CVPR,dense captioning,object detection|http://openaccess.thecvf.com/content_CVPR_2019/papers/Yin_Context_and_Attribute_Grounded_Dense_Captioning_CVPR_2019_paper.pdf|https://github.com/gjyin91/CAG-Net
|Fast, Diverse and Accurate Image Captioning Guided By Part-of-Speech|CVPR2019,CVPR,diversity,template|http://openaccess.thecvf.com/content_CVPR_2019/papers/Deshpande_Fast_Diverse_and_Accurate_Image_Captioning_Guided_by_Part-Of-Speech_CVPR_2019_paper.pdf|
|Unsupervised Image Captioning|CVPR2019,CVPR,unsupervised,unpaired,GAN|https://arxiv.org/pdf/1811.10787.pdf|https://github.com/fengyang0317/unsupervised_captioning?
|Describing like Humans: on Diversity in Image Captioning|CVPR2019,CVPR,diversity,metric|https://arxiv.org/pdf/1903.12020.pdf|https://github.com/qingzwang/DiversityMetrics
|CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection|CVPR2019,CVPR,caption guided|http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_CapSal_Leveraging_Captioning_to_Boost_Semantics_for_Salient_Object_Detection_CVPR_2019_paper.pdf|https://github.com/zhangludl/code-and-dataset-for-CapSal?
|Auto-Encoding Scene Graphs for Image Captioning|CVPR2019,CVPR,graph,object detection|https://arxiv.org/pdf/1812.02378.pdf|
|Attention Is All You Need|2017,model,language model|https://arxiv.org/pdf/1706.03762.pdf|https://github.com/tensorflow/tensor2tensor
|BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding|2018,model,language model|https://arxiv.org/pdf/1810.04805.pdf|https://github.com/google-research/bert
|XLNet: Generalized Autoregressive Pretraining for Language Understanding|2019,model language model|https://arxiv.org/pdf/1906.08237.pdf|https://github.com/zihangdai/xlnet
|Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning|CVPR2017,CVPR,model,attention|https://arxiv.org/pdf/1612.01887.pdf|https://github.com/jiasenlu/AdaptiveAttention
|Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering|CVPR2018,CVPR,model,attention|https://arxiv.org/pdf/1707.07998.pdf|https://github.com/peteanderson80/bottom-up-attention
|SPICE: Semantic Propositional Image Caption Evaluation|ECCV2016,ECCV,metric|https://arxiv.org/pdf/1607.08822.pdf|
|Layer Normalization|2016,architecture|https://arxiv.org/pdf/1607.06450.pdf|
|Learning to Evaluate Image Captioning|CVPR2018,CVPR,metric|https://arxiv.org/pdf/1806.06422.pdf|https://github.com/richardaecn/cvpr18-caption-eval
|Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present|CVPR2018,CVPR,model|https://arxiv.org/pdf/1803.11439.pdf|https://github.com/chenxinpeng/ARNet
|Discriminability objective for training descriptive captions|CVPR2018,CVPR,diversity|https://arxiv.org/abs/1803.04376|https://github.com/ruotianluo/DiscCaptioning
|Convolutional Image Captioning|CVPR2018,CVPR,model|https://arxiv.org/pdf/1711.09151.pdf|https://github.com/aditya12agd5/convcap
|StyleNet: Generating Attractive Visual Captions with Styles|CVPR2018,CVPR,style,unpaired,unsupervised|https://www.microsoft.com/en-us/research/uploads/prod/2017/06/Generating-Attractive-Visual-Captions-with-Styles.pdf|
|Neural Baby Talk|CVPR2018,CVPR,object detection,model,template|https://arxiv.org/pdf/1803.09845.pdf|https://github.com/jiasenlu/NeuralBabyTalk|Human Attention in Visual Question Answering:
Do Humans and Deep Networks Look at the Same Regions?|2016,explainable,attention|https://arxiv.org/pdf/1606.03556.pdf||GroupCap: Group-based Image Captioning with Structured Relevance and
Diversity Constraints|CVPR2018,CVPR,diversity|http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_GroupCap_Group-Based_Image_CVPR_2018_paper.pdf|
|SCA-CNN: Spatial and Channel-wise Attention in Convolutional Networks
for Image Captioning|CVPR2017,CVPR,attention,model|https://arxiv.org/pdf/1611.05594.pdf|
|Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition|CVPR2017,CVPR,template,semantic|https://arxiv.org/pdf/1704.06972.pdf|
|Deep Reinforcement Learning-based Image Captioning with Embedding Reward|CVPR2017,CVPR,RL|https://arxiv.org/pdf/1704.03899.pdf|
|Attend to You: Personalized Image Captioning with Context Sequence Memory Networks|CVPR2017,CVPR,diversity|http://openaccess.thecvf.com/content_cvpr_2017/papers/Park_Attend_to_You_CVPR_2017_paper.pdf|
|Context-aware Captions from Context-agnostic Supervision|CVPR2017,CVPR,diversity|http://openaccess.thecvf.com/content_cvpr_2017/papers/Vedantam_Context-Aware_Captions_From_CVPR_2017_paper.pdf|
|SemStyle: Learning to Generate Stylised Image Captions using Unaligned Text|CVPR2018,CVPR,unpaired,style|http://openaccess.thecvf.com/content_cvpr_2018/papers/Mathews_SemStyle_Learning_to_CVPR_2018_paper.pdf|https://github.com/computationalmedia/semstyle
|Dense Captioning with Joint Inference and Visual Context|CVPR2017,CVPR,dense captioning|http://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_Dense_Captioning_With_CVPR_2017_paper.pdf|
|Semantic Compositional Networks for Visual Captioning|CVPR2017,CVPR,semantic|http://openaccess.thecvf.com/content_cvpr_2017/papers/Gan_Semantic_Compositional_Networks_CVPR_2017_paper.pdf|https://github.com/zhegan27/Semantic_Compositional_Nets|
|Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects|CVPR2017,CVPR,novel object captioning,semantic|http://openaccess.thecvf.com/content_cvpr_2017/papers/Yao_Incorporating_Copying_Mechanism_CVPR_2017_paper.pdf|
|Captioning Images with Diverse Objects|CVPR2017,CVPR,novel object captioning,semantic|http://openaccess.thecvf.com/content_cvpr_2017/papers/Venugopalan_Captioning_Images_With_CVPR_2017_paper.pdf|https://vsubhashini.github.io/noc.html
|Top-down Visual Saliency Guided by Captions|CVPR2017,CVPR,caption guided,saliency prediction|http://openaccess.thecvf.com/content_cvpr_2017/papers/Ramanishka_Top-Down_Visual_Saliency_CVPR_2017_paper.pdf|https://vsubhashini.github.io/noc.html
|Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-in-the-Blank Image Captioning|CVPR2017,CVPR,beam search|http://openaccess.thecvf.com/content_cvpr_2017/papers/Sun_Bidirectional_Beam_Search_CVPR_2017_paper.pdf|
|Beyond instance-level image retrieval:Leveraging captions to learn a global visual representation for semantic retrieval|CVPR2017,CVPR,caption guided|http://openaccess.thecvf.com/content_cvpr_2017/papers/Gordo_Beyond_Instance-Level_Image_CVPR_2017_paper.pdf|
|Areas of Attention for Image Captioning|ICCV2017,ICCV,attention|http://openaccess.thecvf.com/content_ICCV_2017/papers/Pedersoli_Areas_of_Attention_ICCV_2017_paper.pdf|https://github.com/marcopede/AreasOfAttention
|An Empirical Study of Language CNN for Image Captioning|ICCV2017,ICCV,language CNN,model|http://openaccess.thecvf.com/content_ICCV_2017/papers/Gu_An_Empirical_Study_ICCV_2017_paper.pdf|
|Scene Graph Generation from Objects, Phrases and Region Captions|ICCV2017,ICCV,scene graph,semantic|http://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Scene_Graph_Generation_ICCV_2017_paper.pdf|https://github.com/yikang-li/MSDN
|Improved Image Captioning via Policy Gradient optimization of SPIDEr|ICCV2017,ICCV,RL,metric|http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Improved_Image_Captioning_ICCV_2017_paper.pdf|
|Speaking the Same Language:Matching Machine to Human Captions by Adversarial Training|ICCV2017,ICCV,GAN,diversity|http://openaccess.thecvf.com/content_ICCV_2017/papers/Shetty_Speaking_the_Same_ICCV_2017_paper.pdf|
|Paying Attention to Descriptions Generated by Image Captioning Models|ICCV2017,ICCV,explainable|http://openaccess.thecvf.com/content_ICCV_2017/papers/Tavakoli_Paying_Attention_to_ICCV_2017_paper.pdf|
|Boosting Image Captioning with Attributes|ICCV2017,ICCV,semantic|http://openaccess.thecvf.com/content_ICCV_2017/papers/Yao_Boosting_Image_Captioning_ICCV_2017_paper.pdf|
|Dynamic Routing Between Capsules|NIPS2017,NIPS,model|https://arxiv.org/pdf/1710.09829.pdf|https://github.com/adambielski/CapsNet-pytorch
|Boosted Attention: Leveraging Human Attention for Image Captioning|ECCV2018,ECCV,attention,semantic|http://openaccess.thecvf.com/content_ECCV_2018/papers/Shi_Chen_Boosted_Attention_Leveraging_ECCV_2018_paper.pdf|
|Show, Adapt and Tell: Adversarial Training of Cross-domain Image Captioner|ICCV2017,ICCV,GAN,unpaired|http://openaccess.thecvf.com/content_ICCV_2017/papers/Chen_Show_Adapt_and_ICCV_2017_paper.pdf|https://github.com/tsenghungchen/show-adapt-and-tell
|Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data|ECCV2018,ECCV,diversity|http://openaccess.thecvf.com/content_ECCV_2018/papers/Xihui_Liu_Show_Tell_and_ECCV_2018_paper.pdf|
|Going Deeper with Convolutions|CVPR2015,CVPR|https://arxiv.org/pdf/1409.4842.pdf|
|Unpaired Image Captioning by Language Pivoting|ECCV2018,ECCV,unpaired|http://openaccess.thecvf.com/content_ECCV_2018/papers/Jiuxiang_Gu_Unpaired_Image_Captioning_ECCV_2018_paper.pdf|
|Rethinking the Form of Latent States in Image Captioning|ECCV2018,ECCV,model|http://openaccess.thecvf.com/content_ECCV_2018/papers/Jiuxiang_Gu_Unpaired_Image_Captioning_ECCV_2018_paper.pdf|
|Women Also Snowboard:Overcoming Bias in Captioning Models|ECCV2018,ECCV,dataset bias|http://openaccess.thecvf.com/content_ECCV_2018/papers/Lisa_Anne_Hendricks_Women_also_Snowboard_ECCV_2018_paper.pdf|
|NNEval: Neural Network based Evaluation Metric for Image Captioning|ECCV2018,ECCV,metric|http://openaccess.thecvf.com/content_ECCV_2018/papers/Naeha_Sharif_NNEval_Neural_Network_ECCV_2018_paper.pdf|
|How Does Batch Normalization Help Optimization?|NIPS2018,architecture,explainable|https://arxiv.org/pdf/1805.11604.pdf|
|Factual” or Emotional”: Stylized Image Captioning with Adaptive Learning and Attention|ECCV2018,ECCV,style|http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianlang_Chen_Factual_or_Emotional_ECCV_2018_paper.pdf|
|Recurrent Fusion Network for Image Captioning|ECCV2018,ECCV,encoder|http://openaccess.thecvf.com/content_ECCV_2018/papers/Wenhao_Jiang_Recurrent_Fusion_Network_ECCV_2018_paper.pdf|
|Exploring Visual Relationship for Image Captioning|ECCV2018,ECCV,semantic,scene graph|http://openaccess.thecvf.com/content_ECCV_2018/papers/Ting_Yao_Exploring_Visual_Relationship_ECCV_2018_paper.pdf|
|Densely Connected Convolutional Networks|CVPR2017,CVPR,best paper,model|https://arxiv.org/pdf/1608.06993.pdf|
|Detecting Visual Relationships with Deep Relational Networks|CVPR2017,CVPR,semantic|http://openaccess.thecvf.com/content_cvpr_2017/papers/Dai_Detecting_Visual_Relationships_CVPR_2017_paper.pdf|
